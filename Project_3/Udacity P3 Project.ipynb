{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Project P3: Wrangle OpenStreetMap Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "I used an OpenStreetMap export of the area of Paderborn, Germany, the place where I live."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data audit and inconsistencies\n",
    "\n",
    "Before converting the OpenStreetMap XML file to a JSON, I audited the data for inconsistencies.\n",
    "\n",
    "#### Street adresses\n",
    "The street adresses looked fine to me. German street have a large variety of endings. The most common is \"Straße\" and \"Weg\". However, there are countless more and sometimes they are written with a \"-\", sometimes with a space and sometimes as a single word, so it's nearly impossible to check whether this is a valid name or not. I checked if there were any abbreviations but couldn't find any in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postocdes\n",
    "Then I checked the postcodes: all postcodes should have 5 digits and start with 3 or 5, which is correct for Paderborn and the surrounding areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85053\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "\n",
    "osmfile = \"paderborn.osm\"\n",
    "osmjsonfile = \"paderborn.osm.json\"\n",
    "\n",
    "for _, element in ET.iterparse(osmfile):\n",
    "    if element.tag == \"way\":\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if tag.attrib['k'] == \"addr:postcode\":\n",
    "                if len(tag.attrib['v']) != 5:\n",
    "                    print(tag.attrib['v'])\n",
    "                if tag.attrib['v'][0] != \"3\" and tag.attrib['v'][0] != \"5\":\n",
    "                    print(tag.attrib['v'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is obviously one wrong postcode in the data. However, when I checked the entry I found that this is the address of a chainstore where someone entered the address of the central office."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Phone numbers\n",
    "The phone numbers were really inconsistent. Some had the country code for Germany, so they were starting with \"+49\" or \"0049\". The continuation after this code was also inconsistent: some included the following \"0\", some did not.\n",
    "There were also some mobile phone numbers (beginning with 017..., for example) and some service numbers (starting with 0800...).\n",
    "\n",
    "I also noticed that there were some \"emergency_access_point\" in the dataset which had set the phone number \"112\", so in order to leave these numbers as they are, I also added that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_phone(phone_number):\n",
    "    # http://stackoverflow.com/questions/6116978/python-replace-multiple-strings\n",
    "\n",
    "    rep = {\"-\": \"\", \"(\": \"\", \")\": \"\", \"/\": \"\", \" \": \"\",\"-\": \"\", \"+\": \"\", \".\": \"\"}\n",
    "    rep = dict((re.escape(k), v) for k, v in rep.iteritems())\n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    phone_number = pattern.sub(lambda m: rep[re.escape(m.group(0))], phone_number)\n",
    "\n",
    "    if phone_number[:2] == \"49\":\n",
    "         phone_number = \"0\" + phone_number[2:]\n",
    "\n",
    "    if phone_number[:4] == \"0049\":\n",
    "         phone_number = phone_number[4:]\n",
    "\n",
    "    if phone_number[:2] == \"00\":\n",
    "         phone_number = phone_number[1:]\n",
    "\n",
    "    if phone_number[0] != \"0\" and phone_number != \"112\":\n",
    "        phone_number = \"0\" + phone_number\n",
    "\n",
    "    return phone_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisines\n",
    "\n",
    "Some restaurants also have some information about the cuisine they offer. I noticed some inconsistencies regarding the spelling or formatting. There were also four entries with German descriptions.\n",
    "Furthermore, there were some values with several cuisines seperated by semicolons, so I split them, checked every single value and converted them back to a string again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_cuisines = [\"asian\", \"thai\", \"regional\", \"ice_cream\", \"chinese\",\n",
    "                    \"turkish\", \"german\", \"pizza\", \"mexican\", \"italian\",\n",
    "                    \"indian\", \"steak_house\", \"argentinian\", \"greek\", \"russian\",\n",
    "                    \"kebab\", \"french\", \"burger\", \"oriental\", \"sausages\",\n",
    "                    \"cake\", \"shisha\", \"spanish\", \"donuts\", \"vietnamese\",\n",
    "                    \"lahmacun\", \"tapas\", \"sandwich\", \"pasta\", \"salad\", \"sushi\",\n",
    "                    \"japanese\", \"balkan\", \"international\"]\n",
    "\n",
    "cuisine_mapping = {\n",
    "                    \"Wok und mehr\": \"asian\",\n",
    "                    \"Wurst\": \"sausages\",\n",
    "                    \"Balkan und internationale Speisen\": \"balkan; international\",\n",
    "                    \"icecream\": \"ice_cream\",\n",
    "                    \"german and french\": \"german; french\",\n",
    "                    \"Kuchen,_Flammkuchen,_Espresso,_Capppuccino,Getränke\":\n",
    "                    \"cake; tarte flambée; coffee; drinks\"\n",
    "                    }\n",
    "\n",
    "def update_cuisine(cuisine):\n",
    "    if cuisine not in expected_cuisines:\n",
    "        if cuisine in cuisine_mapping:\n",
    "            cuisine = cuisine_mapping[cuisine]\n",
    "        elif \",\" in cuisine:\n",
    "            cuisine = cuisine.replace(\",\", \";\")\n",
    "        if \";\" in cuisine:\n",
    "            cuisine_list = cuisine.split(';')\n",
    "            for i in xrange(len(cuisine_list)):\n",
    "                if cuisine_list[i] in cuisine_mapping:\n",
    "                    cuisine_list[i] = cuisine_mapping[cuisine_list[i]]\n",
    "            cuisine = \";\".join(cuisine_list)\n",
    "    return cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client[\"udacity\"]\n",
    "paderborn = db.paderborn_osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesizes:\n",
      "The original OSM file is 310.451692 MB\n",
      "The original JSON file is 333.523074 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Filesizes:\")\n",
    "print('The original OSM file is {} MB'.format(os.path.getsize(osmfile)/1.0e6))\n",
    "print('The original JSON file is {} MB'.format(os.path.getsize(osmjsonfile)/1.0e6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 906\n"
     ]
    }
   ],
   "source": [
    "print(\"Users: {}\".format(len(paderborn.distinct(\"created.user\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1479054\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents: {}\".format(paderborn.find().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1266754\n",
      "Number of ways: 212194\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nodes:\",paderborn.find({'type':'node'}).count())\n",
    "print(\"Number of ways:\",paderborn.find({'type':'way'}).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration\n",
    "### Top 10 leisure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'pitch', 'count': 557}, {'_id': 'playground', 'count': 486}, {'_id': 'park', 'count': 168}, {'_id': 'sports_centre', 'count': 138}, {'_id': 'nature_reserve', 'count': 122}, {'_id': 'garden', 'count': 117}, {'_id': 'common', 'count': 95}, {'_id': 'picnic_table', 'count': 44}, {'_id': 'swimming_pool', 'count': 36}, {'_id': 'horse_riding', 'count': 27}]\n"
     ]
    }
   ],
   "source": [
    "leisure = paderborn.aggregate([{'$match': {'leisure': {'$exists': 1}}},\n",
    "                                {'$group': {'_id': '$leisure',\n",
    "                                            'count': {'$sum': 1}}}, \n",
    "                                {'$sort': {'count': -1}},\n",
    "                                {'$limit': 10}])\n",
    "print(list(leisure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'bench', 'count': 4031}, {'_id': 'parking', 'count': 1676}, {'_id': 'waste_basket', 'count': 822}, {'_id': 'vending_machine', 'count': 675}, {'_id': 'bicycle_parking', 'count': 455}, {'_id': 'recycling', 'count': 374}, {'_id': 'restaurant', 'count': 287}, {'_id': 'post_box', 'count': 281}, {'_id': 'place_of_worship', 'count': 276}, {'_id': 'shelter', 'count': 250}]\n"
     ]
    }
   ],
   "source": [
    "amenity = paderborn.aggregate([{'$match': {'amenity': {'$exists': 1}}},\n",
    "                                {'$group': {'_id': '$amenity',\n",
    "                                            'count': {'$sum': 1}}}, \n",
    "                                {'$sort': {'count': -1}},\n",
    "                                {'$limit': 10}])\n",
    "print(list(amenity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benches\n",
    "\n",
    "Funny enough, the most found amenity are benches. There are quite a lot of lakes here, all surrounded by waling and bicycle paths, so this is somehow reasonable. A quick look into the data revealed that there is even more information about these benches:\n",
    "\n",
    "#### Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'wood', 'count': 2203}, {'_id': None, 'count': 845}, {'_id': 'metal', 'count': 753}]\n"
     ]
    }
   ],
   "source": [
    "bench_material = paderborn.aggregate([{'$match':{'amenity': 'bench'}},\n",
    "        {'$group':{'_id':'$material',\n",
    "                   'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':3}])\n",
    "\n",
    "print(list(bench_material))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'brown', 'count': 2119}, {'_id': None, 'count': 957}, {'_id': 'green', 'count': 345}]\n"
     ]
    }
   ],
   "source": [
    "bench_colour = paderborn.aggregate([{'$match':{'amenity': 'bench'}},\n",
    "        {'$group':{'_id':'$colour',\n",
    "                   'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':3}])\n",
    "\n",
    "print(list(bench_colour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': '3', 'count': 2642}, {'_id': None, 'count': 968}, {'_id': '4', 'count': 148}]\n"
     ]
    }
   ],
   "source": [
    "bench_seats = paderborn.aggregate([{'$match':{'amenity': 'bench'}},\n",
    "        {'$group':{'_id':'$seats',\n",
    "                   'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':3}])\n",
    "\n",
    "print(list(bench_seats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Opening hours\n",
    "\n",
    "After information about benches was so detailed, I also checked the information about opening hours of resturants in order to find out if there were opening hours available and if yes, if they were just some kind of placeholder or detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None, 'count': 158}, {'_id': 'Mo-Su 11:00-23:00', 'count': 2}, {'_id': 'Mo-Su 11:30-23:00', 'count': 2}, {'_id': 'off', 'count': 2}, {'_id': 'Mo-Su 09:00+', 'count': 2}, {'_id': 'Mo-Sa 11:30-15:00, 18:00-22:30; Su off', 'count': 1}, {'_id': 'Mo-Fr 17:00-01:00, Sa,Su,PH 09:00-01:00', 'count': 1}, {'_id': 'Tu-Fr 10:45-14:30, 17:00-23:00; Sa-Mo 16:00-23:00', 'count': 1}, {'_id': 'Tu-Su 12:00-15:00,18:00-24:00', 'count': 1}, {'_id': 'We-Su 11:30-22:30; Mo-Tu off', 'count': 1}]\n"
     ]
    }
   ],
   "source": [
    "restaurant_opening = paderborn.aggregate([{'$match':{'amenity': 'restaurant'}},\n",
    "        {'$group':{'_id':'$opening_hours',\n",
    "                   'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':10}])\n",
    "\n",
    "print(list(restaurant_opening))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None, 'count': 110}, {'_id': 'italian', 'count': 31}, {'_id': 'pizza', 'count': 27}, {'_id': 'german', 'count': 25}, {'_id': 'regional', 'count': 22}, {'_id': 'greek', 'count': 17}, {'_id': 'indian', 'count': 8}, {'_id': 'chinese', 'count': 5}, {'_id': 'asian', 'count': 5}, {'_id': 'steak_house', 'count': 4}]\n"
     ]
    }
   ],
   "source": [
    "restaurant_opening = paderborn.aggregate([{'$match':{'amenity': 'restaurant'}},\n",
    "        {'$group':{'_id':'$cuisine',\n",
    "                   'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':10}])\n",
    "\n",
    "print(list(restaurant_opening))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Other ideas about the datasets\n",
    "\n",
    "### Improvement of the current data\n",
    "When I did some research on OSM and formats or tags used, I stumbled upon some website with local OSM groups and there was also one in Paderborn (which obviously isn't active anymore, but it existed). Furthermore, as shown above, 906 users worked on the data. For that reason I expected to have only a few inconsistencies and problems. That was only partly true.\n",
    "\n",
    "#### Phone numbers\n",
    "As mentioned above, the format of the phone numbers was inconsistent. I think I have shown that it is really easy to make them consistent and especially reduce wrongly formatted numbers. I am surprised that nobody did that yet. \n",
    "\n",
    "\n",
    "#### Possible improvements\n",
    "Additionally, I think the focus people had when creating the data was not that optimal. It's funny to have detailed data about benches, but I can't think of any practical need for that. In contrast, there are 158 restaurants without any information about opening hours, which is definitely a more important information. It might be difficult to find a good and consistent format, but I think it would be worth implementing and standardizing it.\n",
    "\n",
    "A suggestion could be:\n",
    "* 2-letter abbreviations for every day: mo, tu, we, th, fr, sa, su\n",
    "* After each abbreviation we use a 4-digit integer representing the opening hours in a 24-hour format\n",
    "* There could be other abbreviations to summarize groups of days (for example \"wd\" for weekdays) or specify opening hours for holidays.\n",
    "* If the amenity is closed on one day, this could be simply left out.\n",
    "\n",
    "So if we want to use this schema for a shop with opening hours from 10 to 20 on weekdays, from 10 to 18 on Saturdays and closed on Sundays this could be: \"wd1020sa1020\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Further ideas\n",
    "The first review of this project provided me with a nice idea which I think is quite neat: adding Pokémon Go data to OSM.\n",
    "There are three things which are important for Pokémon Go players: Pokéstops, Gyms and, of course, spawn points of Pokémons. As the latter is changing often it's not possible to represent them on a static map.\n",
    "What is way more interesting are the places of Pokéstops and Gyms. They can be specified by their coordinates - basically the same as any other location.\n",
    "\n",
    "**Benefits**:\n",
    "* More users, who could also help to improve the quality of the maps.\n",
    "* Neat tool for all Pokémon Go players as this can be used to plan walking routes (most efficient way to visit x Pokéstops) or find other interesting places.\n",
    "\n",
    "**Anticipated problems**:\n",
    "* Pokémon Go data is only interesting for a small number of people compared to the number of people who use OSM. Therefore, it is a large amount of data for a small group of people.\n",
    "* This data adds more temporary data. Although you could say that for other information as well, I think you can say that game data is changing more frequently than data from the \"real world\"."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
